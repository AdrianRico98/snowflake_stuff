{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "mfa42rbvzew32ybtbwlq",
   "authorId": "4487983831522",
   "authorName": "ADRIANRICO98",
   "authorEmail": "adrian.rico.analytics@gmail.com",
   "sessionId": "a58fd028-dc41-4c9f-b470-591a4d1ac1a7",
   "lastEditTime": 1742743263391
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "name": "markdown",
    "collapsed": false
   },
   "source": "# Analizador Inteligente de Curr칤culums con Snowflake y OCR\n\n## 쯈u칠 es OCR y por qu칠 es 칰til para procesar curr칤culums?\n\nEl Reconocimiento 칍ptico de Caracteres (OCR) es una tecnolog칤a que permite convertir diferentes tipos de documentos, como im치genes escaneadas, archivos PDF o fotograf칤as de documentos, en datos editables y con capacidad de b칰squeda. En el contexto de los curr칤culums vitae, el OCR es particularmente valioso porque:\n\n- **Automatiza la extracci칩n de informaci칩n**: Permite procesar grandes vol칰menes de CVs sin intervenci칩n manual.\n- **Facilita la b칰squeda**: Convierte documentos que antes eran solo im치genes en texto sobre el que podemos realizar consultas.\n- **Habilita el an치lisis avanzado**: Posibilita la aplicaci칩n de t칠cnicas de NLP y machine learning sobre el contenido extra칤do.\n\n## Arquitectura RAG: Mejorando las respuestas con contexto\n\nEste proyecto utiliza la arquitectura RAG (Retrieval-Augmented Generation) que combina:\n\n1. **Retrieval (Recuperaci칩n)**: Usando vectores de embedding para encontrar los fragmentos m치s relevantes de los curr칤culums.\n2. **Augmentation (Aumento)**: Proporcionando este contexto relevante al modelo de lenguaje.\n3. **Generation (Generaci칩n)**: Utilizando un modelo de lenguaje para generar respuestas precisas basadas en el contexto.\n"
  },
  {
   "cell_type": "code",
   "id": "160fa39b-8199-4e6c-91ea-f08205e439b9",
   "metadata": {
    "language": "python",
    "name": "imports"
   },
   "outputs": [],
   "source": "# Importar paquetes de Python\nimport streamlit as st\nimport tesserocr\nimport io\nfrom PIL import Image\nimport pandas as pd  # Para an치lisis de datos extra칤dos\n\n# Utilizamos Snowpark\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark.types import StringType, StructField, StructType, IntegerType\nfrom snowflake.snowpark.files import SnowflakeFile\nfrom snowflake.core import CreateMode\nfrom snowflake.core.table import Table, TableColumn\nfrom snowflake.core.schema import Schema\nfrom snowflake.core import Root\n\nsession = get_active_session()\nsession.use_schema(\"curriculum_schema\")\nroot = Root(session)\ndatabase = root.databases[session.get_current_database()]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "tabla_embeddings"
   },
   "source": "#Creamos la tabla que va a alojar los distintos chunks y los vectores para hacer el retrieval\ncvs_chunks_table = Table(\n    name=\"cvs_chunks_table\",\n    columns=[\n        TableColumn(name=\"relative_path\", datatype=\"string\"),\n        TableColumn(name=\"file_url\", datatype=\"string\"),\n        TableColumn(name=\"scoped_file_url\", datatype=\"string\"),\n        TableColumn(name=\"chunk\", datatype=\"string\"),\n        TableColumn(name=\"chunk_vec\", datatype=\"vector(float,768)\")\n    ]\n)\ndatabase.schemas[\"curriculum_schema\"].tables.create(cvs_chunks_table, mode=CreateMode.or_replace)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cvtext_function"
   },
   "source": "#Cremos la clase que procesa el ocr con tesserocr y la registres como una user defined table function que podamos aplicar de forma iterativa para cada url/stage file\nclass CvText:\n    def process(self, file_url: str):\n        with SnowflakeFile.open(file_url, 'rb') as f:\n            buffer = io.BytesIO(f.readall())\n        image = Image.open(buffer)\n        text = tesserocr.image_to_text(image)\n        yield (text,)  \n\noutput_schema = StructType([\n    StructField(\"full_text\", StringType())\n])\n\nsession.udtf.register(\n    CvText,\n    name=\"CV_TEXT\",\n    is_permanent=True,\n    stage_location=\"@curriculum_schema.cvs_to_ocr\",\n    schema=\"curriculum_schema\",\n    output_schema=output_schema,\n    packages=[\"tesserocr\", \"pillow\", \"snowflake-snowpark-python\"],\n    replace=True\n)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c0fcb397-c0db-469f-affe-84e25ce69776",
   "metadata": {
    "language": "sql",
    "name": "ejemplo"
   },
   "outputs": [],
   "source": "--Mostramos el uso de la funci칩n creada sobre cada cv del stage\nSELECT \n    relative_path, \n    file_url, \n    build_scoped_file_url(@curriculum_schema.cvs_to_ocr, relative_path) AS scoped_file_url,\n    ocr_result.full_text,\nFROM \n    directory(@curriculum_schema.cvs_to_ocr),\n    TABLE(CV_TEXT(build_scoped_file_url(@curriculum_schema.cvs_to_ocr, relative_path))) AS ocr_result;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cb59a530-eed8-4b6f-a935-0be160eed53f",
   "metadata": {
    "language": "sql",
    "name": "temp_table"
   },
   "outputs": [],
   "source": "--Creamos una tabla intermedia que aloje los resultados obtenidos del ocr y que vectorizaremos e insertaremos en la tabla fija en el siguiente bloque\nCREATE OR REPLACE TEMPORARY TABLE temp_ocr_results AS\nSELECT \n    relative_path, \n    file_url, \n    build_scoped_file_url(@curriculum_schema.cvs_to_ocr, relative_path) AS scoped_file_url,\n    ocr_result.full_text,\nFROM \n    directory(@curriculum_schema.cvs_to_ocr),\n    TABLE(CV_TEXT(build_scoped_file_url(@curriculum_schema.cvs_to_ocr, relative_path))) AS ocr_result;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5b2843cd-c39d-4347-8ceb-8674c5567bee",
   "metadata": {
    "language": "sql",
    "name": "embeddings_insercion"
   },
   "outputs": [],
   "source": "-- Insertamos los chunks con vectorizaci칩n en la tabla fija\nDELETE FROM cvs_chunks_table;\nINSERT INTO cvs_chunks_table (\n    relative_path, \n    file_url, \n    scoped_file_url, \n    chunk, \n    chunk_vec\n)\nSELECT \n    relative_path, \n    file_url,\n    scoped_file_url,\n    chunk.value,\n    SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', chunk.value) AS chunk_vec -- usamos el modelo de embedding disponible de snowflake para vectorizar en vectores de 768 dimensiones el contenido de cada chunk\n\nFROM\n    temp_ocr_results,\n    LATERAL FLATTEN(SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER(full_text,'none', 2000, 300)) chunk;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e7c760f-801e-4fd9-bc5a-71ac6cd3670f",
   "metadata": {
    "language": "python",
    "name": "streamlit"
   },
   "outputs": [],
   "source": "import streamlit as st\nimport pandas as pd\n\n# Par치metros configurables\nmodel = \"mistral-7b\"\nnum_chunks = 10  #fragmentos de contexto, no igual a cvs (10 porque se han generado 10 chunks de los cvs del stage)\n\ndef create_prompt(pregunta):\n    # Consulta para recuperar contexto\n    cmd = \"\"\"\n     WITH results AS\n     (SELECT RELATIVE_PATH,\n       VECTOR_COSINE_SIMILARITY(cvs_chunks_table.chunk_vec,\n                SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', ?)) as similarity,\n       chunk\n     FROM cvs_chunks_table\n     ORDER BY similarity DESC\n     LIMIT ?)\n     SELECT chunk, relative_path, similarity FROM results \n     \"\"\"\n    df_context = session.sql(cmd, params=[pregunta, num_chunks]).to_pandas()      \n    \n    # Recolectamos todos los paths 칰nicos de los archivos usados\n    unique_paths = df_context['RELATIVE_PATH'].unique()\n    \n    # Creamos contexto para el prompt\n    prompt_context = \" \".join(df_context['CHUNK'].tolist())\n    prompt_context = prompt_context.replace(\"'\", \"\")\n  \n    prompt = f\"\"\"\n      'Eres un asistente experto en extraer informaci칩n de curr칤culums.\n       Responde a la pregunta bas치ndote en el contexto proporcionado. S칠 conciso y no inventes informaci칩n.\n       Si no tienes la informaci칩n, simplemente dilo.\n       \n      Contexto: {prompt_context}\n      \n      Pregunta:  \n       {pregunta} \n       \n       Respuesta: '\n       \"\"\"\n    \n    # Obtener URLs\n    file_data = []\n    for path in unique_paths:\n        # Filtramos fragmentos relacionados con este archivo\n        file_chunks = df_context[df_context['RELATIVE_PATH'] == path]\n        \n        # Obtenemos URL\n        cmd2 = f\"SELECT GET_PRESIGNED_URL(@curriculum_schema.cvs_to_ocr, '{path}', 3600) AS URL_LINK FROM directory(@curriculum_schema.cvs_to_ocr)\"\n        df_url_link = session.sql(cmd2).to_pandas()\n        url_link = df_url_link._get_value(0, 'URL_LINK')\n        \n        # Crear estructura de datos con informaci칩n relevante\n        file_data.append({\n            \"path\": path, \n            \"url\": url_link,\n            \"chunks\": file_chunks['CHUNK'].tolist(),\n            \"similarity\": file_chunks['SIMILARITY'].max()\n        })\n    \n    # Ordenamos por relevancia (mayor similitud)\n    file_data = sorted(file_data, key=lambda x: x['similarity'], reverse=True)\n    \n    return prompt, file_data\n\ndef analyze_cv(file_info):\n    \"\"\"Analiza el contenido de un CV basado en los fragmentos de texto\"\"\"\n    # Concatenar todos los fragmentos de este archivo\n    full_text = \" \".join(file_info[\"chunks\"])\n    \n    # Prompt para an치lisis del cv\n    analysis_prompt = f\"\"\"\n    'Eres un experto en an치lisis de curr칤culums. \n     Analiza el siguiente fragmento de texto extra칤do de un CV y proporciona un resumen estructurado \n     con los siguientes elementos:\n     \n     1. PERFIL: Breve descripci칩n del perfil profesional\n     2. EXPERIENCIA: Puntos clave de su experiencia laboral\n     3. HABILIDADES: Lista de habilidades principales identificadas\n     4. FORMACI칍N: Informaci칩n sobre su formaci칩n acad칠mica\n     \n     Texto del CV: {full_text} \n     \n     An치lisis: '\n    \"\"\"\n    cmd = \"SELECT SNOWFLAKE.CORTEX.COMPLETE(?, ?) AS analysis\"\n    df_analysis = session.sql(cmd, params=[model, analysis_prompt]).collect()\n    return df_analysis[0]['ANALYSIS']\n\ndef complete(pregunta):\n    prompt, file_data = create_prompt(pregunta)\n    #Utilizamos la funci칩n de cortex \"complete\" para que complete tambi칠n el an치lisis del cv\n    cmd = \"\"\"\n             SELECT SNOWFLAKE.CORTEX.COMPLETE(?, ?) AS response \n           \"\"\"\n    df_response = session.sql(cmd, params=[model, prompt]).collect()\n    \n    # Analizar cada CV 칰nico\n    for file in file_data:\n        file[\"analysis\"] = analyze_cv(file)\n        # Calcular la confianza basada en la similitud\n        file[\"confidence\"] = min(100, int(file[\"similarity\"] * 100))\n    \n    return df_response[0]['RESPONSE'], file_data\n\n\ndef display_response(pregunta):\n    with st.status(\"Analizando documentos...\") as status:\n        try:\n            response, file_data = complete(pregunta)\n            \n            # Mostrar la respuesta principal\n            st.header(\"Respuesta\")\n            st.info(response)\n            \n            # Actualizar el estado\n            status.update(label=\"춰An치lisis completado!\", state=\"complete\", expanded=False)\n            \n            # Mostrar documentos consultados\n            st.header(f\"Documentos consultados ({len(file_data)})\")\n            \n            # Mostrar cada documento en secciones separadas\n            for i, file in enumerate(file_data):\n                st.subheader(f\"Documento {i+1}: {file['path'].split('/')[-1]}\")\n                st.markdown(\"### 游늯 An치lisis del CV\")\n                st.markdown(file[\"analysis\"])\n                \n                # Secci칩n de relevancia\n                st.markdown(\"### 游꿢 Relevancia para la consulta\")\n                col1, col2 = st.columns([3, 1])\n                \n                with col1:\n                    st.progress(file[\"confidence\"]/100)\n                \n                with col2:\n                    # Mostrar porcentaje de relevancia\n                    st.markdown(f\"<h2 style='text-align: center; color: {'green' if file['confidence'] > 60 else 'orange' if file['confidence'] > 20 else 'red'};'>{file['confidence']}%</h2>\", unsafe_allow_html=True)\n                \n                # Descripci칩n sobre la relevancia\n                relevance_description = \"\"\n                if file[\"confidence\"] > 60:\n                    relevance_description = \"Este documento es altamente relevante para tu consulta.\"\n                elif file[\"confidence\"] > 40:\n                    relevance_description = \"Este documento contiene informaci칩n bastante relevante para tu consulta.\"\n                elif file[\"confidence\"] > 20:\n                    relevance_description = \"Este documento es moderadamente relevante para tu consulta.\"\n                else:\n                    relevance_description = \"Este documento tiene baja relevancia, pero puede contener informaci칩n contextual 칰til.\"\n                \n                st.markdown(f\"_{relevance_description}_\")\n                st.markdown(\"---\")\n                \n        except Exception as e:\n            st.error(f\"Error al procesar la consulta: {str(e)}\")\n            status.update(label=\"Error en el procesamiento\", state=\"error\", expanded=True)\n\n# Estilos\nst.markdown(\"\"\"\n<style>\n    h1, h2, h3, h4 {\n        color: #1E88E5;\n    }\n    .relevance-high {\n        background-color: #D5F5E3;\n        padding: 10px;\n        border-radius: 5px;\n        border-left: 5px solid #2ECC71;\n    }\n    .relevance-medium {\n        background-color: #FCF3CF;\n        padding: 10px;\n        border-radius: 5px;\n        border-left: 5px solid #F1C40F;\n    }\n    .relevance-low {\n        background-color: #FADBD8;\n        padding: 10px;\n        border-radius: 5px;\n        border-left: 5px solid #E74C3C;\n    }\n    .stProgress > div > div {\n        height: 20px;\n    }\n</style>\n\"\"\", unsafe_allow_html=True)\n\n# C칩digo principal\nst.title(\"游늼 Consulta Inteligente de Curr칤culums\")\nst.write(\"Haz preguntas sobre los curr칤culums y obt칠n respuestas basadas en la informaci칩n extra칤da mediante OCR\")\n\n# Interfaz de b칰squeda\ncol1, col2 = st.columns([5, 1])\nwith col1:\n    pregunta = st.text_input(\"Ingresa tu pregunta\", placeholder=\"쯈u칠 experiencia tiene este candidato?\")\nwith col2:\n    buscar = st.button(\"游댌 Buscar\", use_container_width=True)\n\nif pregunta and buscar:\n    display_response(pregunta)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fbb2253b-ea69-49e5-b6f6-5b062739873c",
   "metadata": {
    "name": "markdown_conclusiones",
    "collapsed": false
   },
   "source": "# Escalabilidad y L칤neas Futuras de Investigaci칩n\n\n## 츼reas de Exploraci칩n Post-POC\n\nEsta prueba de concepto demuestra el potencial del an치lisis de CVs mediante OCR y arquitectura RAG. Cosas a mejorar:\n\n### Optimizaci칩n de Recursos\n\n- **Persistencia de an치lisis**: Almacenar resultados de an치lisis previos para evitar reprocesamiento de documentos sin cambios.\n- **Procesamiento asincr칩nico**: Implementar mecanismos de procesamiento en segundo plano para grandes vol칰menes de CVs.\n\n### Mejoras T칠cnicas\n\n- **Chunking sem치ntico**: Segmentar documentos seg칰n secciones relevantes de CVs (experiencia, educaci칩n, habilidades).\n- **Indexaci칩n vectorial optimizada**: Explorar t칠cnicas avanzadas de indexaci칩n para b칰squedas m치s eficientes.\n\n### Seguridad Avanzada\n\n- **Enmascaramiento contextual**: Pol칤ticas din치micas basadas en el tipo de informaci칩n detectada.\n- **Control de acceso granular**: Seguridad a nivel de fila y columna para diversos perfiles de usuarios.\n- **Clasificaci칩n autom치tica**: Detecci칩n y etiquetado de informaci칩n sensible en CVs.\n\n### Ampliaci칩n de Capacidades\n\n- **Procesamiento multiling칲e**: Extender el OCR para soportar diversos idiomas y formatos internacionales.\n- **Detecci칩n de tipos de documento**: Clasificaci칩n autom치tica de formatos y estructuras de CV.\n- **Experiencia interactiva**: Mejorar la interfaz para permitir exploraci칩n y refinamiento de resultados.\n- **M칠tricas de calidad**: Implementar sistemas de monitoreo para evaluar la precisi칩n del OCR y RAG.\n- **Cumplimiento normativo**: Adaptaci칩n a diferentes marcos regulatorios (GDPR, CCPA, etc.).\n\nEsta POC sienta las bases para explorar estas interesantes direcciones."
  }
 ]
}